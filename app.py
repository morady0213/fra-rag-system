"""
FRA RAG System - Enhanced Web UI

A Gradio-based web interface for the FRA Regulatory RAG system.
Features:
- Arabic RTL display with proper formatting
- Cited answers with regulation names, article numbers, and exact quotes
- Show Evidence expandable feature
- Anti-hallucination with explicit "not found" responses
- Multi-document reasoning
- Document filtering by type
- Bilingual support (Arabic/English)

Usage:
    python app.py
"""

import gradio as gr
import sys
from pathlib import Path
from typing import Tuple, List, Dict, Any

# Add project root to path
PROJECT_ROOT = Path(__file__).parent.absolute()
sys.path.insert(0, str(PROJECT_ROOT))

from loguru import logger
from config import SAMPLE_DOCS_DIR, RAW_PDFS_DIR

# Configure logging
logger.remove()
logger.add(sys.stderr, format="<green>{time:HH:mm:ss}</green> | <level>{level}</level> | {message}", level="INFO")

# Initialize RAG system (lazy loading)
_rag_system = None
_last_evidence = []  # Store last retrieved evidence for "Show Evidence" feature
_query_history = []  # Store query history
_feedback_log = []  # Store user feedback

# Feedback storage file
FEEDBACK_FILE = PROJECT_ROOT / "data" / "feedback.json"


def save_feedback(query: str, answer: str, feedback: str, timestamp: str):
    """Save user feedback to file."""
    import json
    from datetime import datetime
    
    feedback_entry = {
        "timestamp": timestamp or datetime.now().isoformat(),
        "query": query,
        "answer": answer[:500],  # Truncate for storage
        "feedback": feedback,  # "positive" or "negative"
    }
    
    _feedback_log.append(feedback_entry)
    
    # Save to file
    try:
        FEEDBACK_FILE.parent.mkdir(parents=True, exist_ok=True)
        existing = []
        if FEEDBACK_FILE.exists():
            with open(FEEDBACK_FILE, "r", encoding="utf-8") as f:
                existing = json.load(f)
        existing.append(feedback_entry)
        with open(FEEDBACK_FILE, "w", encoding="utf-8") as f:
            json.dump(existing, f, ensure_ascii=False, indent=2)
        logger.info(f"Feedback saved: {feedback}")
    except Exception as e:
        logger.error(f"Error saving feedback: {e}")

def get_rag_system():
    """Get or initialize the RAG system."""
    global _rag_system
    if _rag_system is None:
        from main import FRARAGSystem
        logger.info("Initializing RAG system...")
        _rag_system = FRARAGSystem()
        
        # Auto-ingest if no documents
        if not _rag_system.is_indexed():
            has_docs = any(SAMPLE_DOCS_DIR.glob("*")) if SAMPLE_DOCS_DIR.exists() else False
            has_pdfs = any(RAW_PDFS_DIR.glob("*.pdf")) if RAW_PDFS_DIR.exists() else False
            if has_docs or has_pdfs:
                logger.info("Ingesting documents...")
                _rag_system.ingest_documents()
    
    return _rag_system


def process_query(
    message: str, 
    history: list, 
    language: str = "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", 
    num_sources: int = 5,
    use_hybrid: bool = True,
    use_rerank: bool = True,
) -> Tuple[str, str]:
    """
    Process a user query and return the answer with evidence.
    
    Args:
        message: User's question
        history: Chat history
        language: Response language
        num_sources: Number of sources to retrieve
        use_hybrid: Enable hybrid search (vector + BM25)
        use_rerank: Enable cross-encoder reranking
        
    Returns:
        Tuple of (answer, evidence_text)
    """
    global _last_evidence
    
    if not message.strip():
        no_question = "Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ø³Ø¤Ø§Ù„." if language == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else "Please enter a question."
        return no_question, ""
    
    try:
        system = get_rag_system()
        
        # Use query router for intelligent retrieval (handles complex/comparison queries)
        if use_hybrid and hasattr(system, 'query_router'):
            retrieval_result = system.query_router.retrieve_with_routing(message, k=num_sources)
            strategy = retrieval_result.get("retrieval_strategy", "unknown")
            logger.info(f"Using query router (strategy={strategy})")
        elif use_hybrid and hasattr(system, 'hybrid_retriever'):
            retrieval_result = system.hybrid_retriever.retrieve_with_context(message, k=num_sources)
            logger.info(f"Using hybrid search (rerank={use_rerank})")
        else:
            retrieval_result = system.retriever.retrieve_with_context(message, k=num_sources)
            logger.info("Using basic vector search")
        context = retrieval_result["context"]
        sources = retrieval_result["sources"]
        
        # Store evidence for "Show Evidence" feature
        _last_evidence = sources
        
        # Build sources text with citations
        sources_text = ""
        if sources:
            if language == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©":
                sources_text = "\n\n---\n### ğŸ“š Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©:\n"
            else:
                sources_text = "\n\n---\n### ğŸ“š Sources Used:\n"
            
            for i, source in enumerate(sources, 1):
                sources_text += f"**{i}.** {source['source']} (relevance: {source['score']:.1%})\n"
        
        # Build evidence text for expandable section
        evidence_text = _build_evidence_text(sources, language)
        
        # Handle no context found (anti-hallucination)
        if not context:
            if language == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©":
                no_info = "**âš ï¸ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†Øµ ØµØ±ÙŠØ­ ÙÙŠ Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©** ÙŠØ¬ÙŠØ¨ Ø¹Ù„Ù‰ Ù‡Ø°Ø§ Ø§Ù„Ø³Ø¤Ø§Ù„ Ù…Ø¨Ø§Ø´Ø±Ø©.\n\nØ§Ù„Ø±Ø¬Ø§Ø¡ ØµÙŠØ§ØºØ© Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¨Ø·Ø±ÙŠÙ‚Ø© Ù…Ø®ØªÙ„ÙØ© Ø£Ùˆ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ØªÙˆÙØ± Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø°Ø§Øª Ø§Ù„ØµÙ„Ø©."
            else:
                no_info = "**âš ï¸ No explicit text in the available documents** directly answers this question.\n\nPlease rephrase your question or ensure relevant documents are available."
            return no_info, evidence_text
        
        # Generate answer with LLM
        if system.llm_client:
            result = system.llm_client.generate(
                query=message,
                context=context,
                sources=[s["source"] for s in sources],
            )
            return result.answer + sources_text, evidence_text
        else:
            if language == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©":
                return f"âš ï¸ LLM ØºÙŠØ± Ù…ØªØ§Ø­\n\n**Ø§Ù„Ø³ÙŠØ§Ù‚:**\n{context[:1500]}..." + sources_text, evidence_text
            else:
                return f"âš ï¸ LLM not available\n\n**Context:**\n{context[:1500]}..." + sources_text, evidence_text
            
    except Exception as e:
        logger.error(f"Error processing query: {e}")
        error_msg = f"Ø­Ø¯Ø« Ø®Ø·Ø£: {e}" if language == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else f"An error occurred: {e}"
        return error_msg, ""


def _build_evidence_text(sources: List[Dict], language: str) -> str:
    """Build formatted evidence text from sources."""
    if not sources:
        if language == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©":
            return "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£Ø¯Ù„Ø© Ù…ØªØ§Ø­Ø©."
        return "No evidence available."
    
    if language == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©":
        evidence = "## ğŸ“– Ø§Ù„Ø£Ø¯Ù„Ø© ÙˆØ§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø³ØªØ±Ø¬Ø¹Ø©\n\n"
        evidence += "Ù‡Ø°Ù‡ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø£ØµÙ„ÙŠØ© Ø§Ù„ØªÙŠ ØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§ Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø³Ø¤Ø§Ù„Ùƒ:\n\n"
    else:
        evidence = "## ğŸ“– Retrieved Evidence & Texts\n\n"
        evidence += "These are the original texts used to answer your question:\n\n"
    
    for i, source in enumerate(sources, 1):
        evidence += f"---\n### ğŸ“Œ Ø§Ù„Ù…ØµØ¯Ø± {i}: {source['source']}\n"
        evidence += f"**Relevance Score:** {source['score']:.1%}\n\n"
        
        # Get the actual content
        content = source.get('content', source.get('text', 'N/A'))
        if content and content != 'N/A':
            evidence += f"```\n{content[:1000]}{'...' if len(content) > 1000 else ''}\n```\n\n"
        else:
            evidence += "_No content available_\n\n"
    
    return evidence


def get_stats() -> str:
    """Get vector store statistics."""
    try:
        system = get_rag_system()
        stats = system.vector_store.get_stats()
        return f"""
**ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Database Statistics)**

| Ø§Ù„Ø­Ù‚Ù„ | Ø§Ù„Ù‚ÙŠÙ…Ø© |
|-------|--------|
| Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© (Collection) | {stats.get('collection_name', 'N/A')} |
| Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª (Documents) | {stats.get('document_count', 0)} |
| Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ¶Ù…ÙŠÙ† (Embedding) | {stats.get('embedding_model', 'N/A')} |
| Ø£Ø¨Ø¹Ø§Ø¯ Ø§Ù„Ù…ØªØ¬Ù‡ (Vector Size) | {stats.get('vector_size', 'N/A')} |
"""
    except Exception as e:
        return f"Ø®Ø·Ø£: {e}"


def upload_and_index_documents(files) -> str:
    """
    Upload documents and index them into the RAG system.
    
    Args:
        files: List of uploaded files from Gradio
        
    Returns:
        Status message
    """
    if not files:
        return "âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ø®ØªÙŠØ§Ø± Ù…Ù„ÙØ§Øª. (No files selected)"
    
    import shutil
    from pathlib import Path
    
    try:
        system = get_rag_system()
        uploaded_files = []
        
        for file in files:
            # Get file path and name
            file_path = Path(file.name) if hasattr(file, 'name') else Path(file)
            file_name = file_path.name
            
            # Copy to sample_docs directory
            dest_path = SAMPLE_DOCS_DIR / file_name
            shutil.copy(str(file_path), str(dest_path))
            uploaded_files.append(file_name)
            logger.info(f"Uploaded: {file_name}")
        
        # Re-ingest documents
        logger.info("Re-indexing documents...")
        count = system.ingest_documents(force=True)
        
        # Reset hybrid retriever BM25 index
        if hasattr(system, 'hybrid_retriever'):
            system.hybrid_retriever._bm25_synced = False
        
        files_list = "\n".join([f"- {f}" for f in uploaded_files])
        return f"""âœ… **ØªÙ… Ø§Ù„Ø±ÙØ¹ Ø¨Ù†Ø¬Ø§Ø­! (Upload Successful!)**

**Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø±ÙÙˆØ¹Ø© ({len(uploaded_files)}):**
{files_list}

**Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø§Ù„Ù…ÙÙ‡Ø±Ø³Ø©:** {count}
"""
    except Exception as e:
        logger.error(f"Upload error: {e}")
        return f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø±ÙØ¹: {e}\n(Upload error: {e})"


def get_available_documents() -> List[str]:
    """Get list of available document names."""
    try:
        system = get_rag_system()
        # This would ideally query the vector store for unique sources
        docs = list(SAMPLE_DOCS_DIR.glob("*.*")) if SAMPLE_DOCS_DIR.exists() else []
        return [doc.name for doc in docs if not doc.name.startswith('.')]
    except:
        return []


# Custom CSS for RTL Arabic support
custom_css = """
.rtl-text {
    direction: rtl;
    text-align: right;
    font-family: 'Segoe UI', 'Arial', 'Tahoma', sans-serif;
}
.gradio-container {
    font-family: 'Segoe UI', 'Arial', 'Tahoma', sans-serif !important;
}
.message {
    direction: rtl;
    text-align: right;
}
.chatbot .message {
    direction: rtl;
    text-align: right;
}
.evidence-box {
    background-color: #f8f9fa;
    border: 1px solid #dee2e6;
    border-radius: 8px;
    padding: 15px;
    margin-top: 10px;
    direction: rtl;
}
.source-tag {
    background-color: #e7f3ff;
    padding: 2px 8px;
    border-radius: 4px;
    font-size: 0.9em;
}
"""

# Create Gradio interface
with gr.Blocks(title="Ù†Ø¸Ø§Ù… FRA RAG") as demo:
    
    # State for storing evidence and last response
    evidence_state = gr.State("")
    last_query_state = gr.State("")
    last_answer_state = gr.State("")
    
    gr.Markdown(
        """
        # ğŸ›ï¸ Ù†Ø¸Ø§Ù… Ø§Ù„Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø§Ù„Ù…Ø¹Ø²Ø² Ù„Ù„Ù‡ÙŠØ¦Ø© Ø§Ù„Ø¹Ø§Ù…Ø© Ù„Ù„Ø±Ù‚Ø§Ø¨Ø© Ø§Ù„Ù…Ø§Ù„ÙŠØ©
        ## FRA RAG System - Financial Regulatory Authority
        
        Ù†Ø¸Ø§Ù… Ø°ÙƒÙŠ Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…ØªØ¹Ù„Ù‚Ø© Ø¨Ù„ÙˆØ§Ø¦Ø­ ÙˆÙ‚Ø±Ø§Ø±Ø§Øª Ø§Ù„Ù‡ÙŠØ¦Ø© Ù…Ø¹ Ø§Ø³ØªØ´Ù‡Ø§Ø¯Ø§Øª Ø¯Ù‚ÙŠÙ‚Ø©
        
        Intelligent Q&A system for FRA regulations with precise citations
        """,
        elem_classes=["rtl-text"]
    )
    
    with gr.Row():
        # Main chat column
        with gr.Column(scale=3):
            chatbot = gr.Chatbot(
                label="Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© (Chat)",
                height=400,
            )
            
            with gr.Row():
                msg = gr.Textbox(
                    label="Ø³Ø¤Ø§Ù„Ùƒ (Your Question)",
                    placeholder="Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ù‡Ù†Ø§... (Type your question here...)",
                    lines=2,
                    rtl=True,
                    scale=4,
                )
                submit_btn = gr.Button("Ø¥Ø±Ø³Ø§Ù„\nSend", variant="primary", scale=1)
            
            # Feedback and action buttons
            with gr.Row():
                thumbs_up_btn = gr.Button("ğŸ‘ Ù…ÙÙŠØ¯ (Helpful)", variant="secondary", scale=1)
                thumbs_down_btn = gr.Button("ğŸ‘ ØºÙŠØ± Ù…ÙÙŠØ¯ (Not Helpful)", variant="secondary", scale=1)
                clear_btn = gr.Button("ğŸ—‘ï¸ Ù…Ø³Ø­ (Clear)", scale=1)
                show_evidence_btn = gr.Button("ğŸ“– Ø§Ù„Ø£Ø¯Ù„Ø© (Evidence)", scale=1)
            
            feedback_status = gr.Markdown("", visible=True)
            
            # Expandable evidence section
            with gr.Accordion("ğŸ“– Ø§Ù„Ø£Ø¯Ù„Ø© ÙˆØ§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø³ØªØ±Ø¬Ø¹Ø© (Retrieved Evidence)", open=False):
                evidence_output = gr.Markdown(
                    value="Ø§Ø·Ø±Ø­ Ø³Ø¤Ø§Ù„Ø§Ù‹ Ù„Ø¹Ø±Ø¶ Ø§Ù„Ø£Ø¯Ù„Ø© Ø§Ù„Ù…Ø³ØªØ±Ø¬Ø¹Ø©...\nAsk a question to see retrieved evidence...",
                    elem_classes=["evidence-box"]
                )
            
            # Query history section
            with gr.Accordion("ğŸ“œ Ø³Ø¬Ù„ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© (Query History)", open=False):
                history_output = gr.Markdown(
                    value="Ù„Ù… ÙŠØªÙ… Ø·Ø±Ø­ Ø£ÙŠ Ø£Ø³Ø¦Ù„Ø© Ø¨Ø¹Ø¯.\nNo questions asked yet."
                )
        
        # Settings column
        with gr.Column(scale=1):
            gr.Markdown("### âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª (Settings)")
            
            language_select = gr.Radio(
                choices=["Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", "English"],
                value="Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©",
                label="Ù„ØºØ© Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© (Response Language)",
            )
            
            num_sources_slider = gr.Slider(
                minimum=1,
                maximum=10,
                value=5,
                step=1,
                label="Ø¹Ø¯Ø¯ Ø§Ù„Ù…ØµØ§Ø¯Ø± (Number of Sources)",
            )
            
            use_hybrid_checkbox = gr.Checkbox(
                value=True,
                label="ğŸ”€ Ø¨Ø­Ø« Ù‡Ø¬ÙŠÙ† (Hybrid Search)",
                info="Ø¯Ù…Ø¬ Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ Ù…Ø¹ Ø§Ù„Ø¨Ø­Ø« Ø¨Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©"
            )
            
            use_rerank_checkbox = gr.Checkbox(
                value=True,
                label="ğŸ¯ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ±ØªÙŠØ¨ (Reranking)",
                info="ØªØ­Ø³ÙŠÙ† Ø¯Ù‚Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ±ØªÙŠØ¨"
            )
            
            gr.Markdown("---")
            
            # Document upload section
            gr.Markdown("### ğŸ“¤ Ø±ÙØ¹ Ù…Ø³ØªÙ†Ø¯ (Upload Document)")
            file_upload = gr.File(
                label="Ø§Ø®ØªØ± Ù…Ù„Ù (Select File)",
                file_types=[".docx", ".pdf", ".txt", ".md"],
                file_count="multiple",
            )
            upload_btn = gr.Button("ğŸ“¥ Ø±ÙØ¹ ÙˆÙÙ‡Ø±Ø³Ø© (Upload & Index)", variant="secondary")
            upload_status = gr.Markdown("")
            
            gr.Markdown("---")
            
            stats_btn = gr.Button("ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª (Statistics)")
            stats_output = gr.Markdown("")
            
            gr.Markdown(
                """
                ---
                ### ğŸ“ Ø£Ù…Ø«Ù„Ø© (Examples)
                
                - Ù…Ø§ Ù‡ÙŠ Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø¥ØµØ¯Ø§Ø± Ø³Ù†Ø¯Ø§Øª Ø§Ù„ØªÙˆØ±ÙŠÙ‚ØŸ
                - Ù…Ø§ Ù‡ÙŠ Ù…ØªØ·Ù„Ø¨Ø§Øª Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ø³Ù†Ø¯Ø§Øª Ø§Ù„Ø®Ø¶Ø±Ø§Ø¡ØŸ
                - Ù…Ø§ Ù‡ÙŠ Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª ØºÙ„Ù‚ ÙØ±Ø¹ Ù„Ø´Ø±ÙƒØ© ØªÙ…ÙˆÙŠÙ„ØŸ
                
                ---
                ### â„¹ï¸ Ù…Ù„Ø§Ø­Ø¸Ø§Øª
                - Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª Ù…Ø¨Ù†ÙŠØ© Ø¹Ù„Ù‰ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø±Ø³Ù…ÙŠØ© ÙÙ‚Ø·
                - Ø§Ø³ØªØ®Ø¯Ù… ğŸ‘/ğŸ‘ Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª
                - Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù‡Ø¬ÙŠÙ† ÙŠØ­Ø³Ù‘Ù† Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù„Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
                """
            )
    
    # Event handlers
    def respond(message, chat_history, language, num_sources, use_hybrid, use_rerank):
        if not message.strip():
            return "", chat_history, "", "", "", get_history_text()
        
        answer, evidence = process_query(
            message, chat_history, language, num_sources, use_hybrid, use_rerank
        )
        chat_history.append({"role": "user", "content": message})
        chat_history.append({"role": "assistant", "content": answer})
        
        # Update query history
        from datetime import datetime
        _query_history.append({
            "timestamp": datetime.now().strftime("%H:%M:%S"),
            "query": message[:100],
            "language": language,
            "hybrid": use_hybrid,
            "rerank": use_rerank,
        })
        
        return "", chat_history, evidence, message, answer, get_history_text()
    
    def get_history_text():
        """Format query history for display."""
        if not _query_history:
            return "Ù„Ù… ÙŠØªÙ… Ø·Ø±Ø­ Ø£ÙŠ Ø£Ø³Ø¦Ù„Ø© Ø¨Ø¹Ø¯.\nNo questions asked yet."
        
        history_md = "| Ø§Ù„ÙˆÙ‚Øª | Ø§Ù„Ø³Ø¤Ø§Ù„ |\n|-------|--------|\n"
        for item in reversed(_query_history[-10:]):  # Last 10 queries
            history_md += f"| {item['timestamp']} | {item['query'][:50]}... |\n"
        return history_md
    
    def update_evidence(evidence):
        return evidence if evidence else "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£Ø¯Ù„Ø© Ù…ØªØ§Ø­Ø© Ø­Ø§Ù„ÙŠØ§Ù‹.\nNo evidence available yet."
    
    def handle_feedback_positive(query, answer):
        """Handle positive feedback."""
        from datetime import datetime
        if query and answer:
            save_feedback(query, answer, "positive", datetime.now().isoformat())
            return "âœ… Ø´ÙƒØ±Ø§Ù‹ Ù„ØªÙ‚ÙŠÙŠÙ…Ùƒ! (Thank you for your feedback!)"
        return ""
    
    def handle_feedback_negative(query, answer):
        """Handle negative feedback."""
        from datetime import datetime
        if query and answer:
            save_feedback(query, answer, "negative", datetime.now().isoformat())
            return "ğŸ“ Ø´ÙƒØ±Ø§Ù‹ Ù„ØªÙ‚ÙŠÙŠÙ…ÙƒØŒ Ø³Ù†Ø¹Ù…Ù„ Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ø³ÙŠÙ†! (Thank you, we'll improve!)"
        return ""
    
    def clear_chat():
        """Clear chat and reset states."""
        return [], "", "", "", get_history_text()
    
    # Connect events
    msg.submit(
        respond, 
        [msg, chatbot, language_select, num_sources_slider, use_hybrid_checkbox, use_rerank_checkbox], 
        [msg, chatbot, evidence_state, last_query_state, last_answer_state, history_output]
    ).then(
        update_evidence,
        [evidence_state],
        [evidence_output]
    )
    
    submit_btn.click(
        respond, 
        [msg, chatbot, language_select, num_sources_slider, use_hybrid_checkbox, use_rerank_checkbox], 
        [msg, chatbot, evidence_state, last_query_state, last_answer_state, history_output]
    ).then(
        update_evidence,
        [evidence_state],
        [evidence_output]
    )
    
    # Feedback buttons
    thumbs_up_btn.click(
        handle_feedback_positive,
        [last_query_state, last_answer_state],
        [feedback_status]
    )
    
    thumbs_down_btn.click(
        handle_feedback_negative,
        [last_query_state, last_answer_state],
        [feedback_status]
    )
    
    clear_btn.click(clear_chat, None, [chatbot, evidence_state, last_query_state, last_answer_state, history_output])
    show_evidence_btn.click(update_evidence, [evidence_state], [evidence_output])
    stats_btn.click(get_stats, None, stats_output)
    
    # Upload button
    upload_btn.click(upload_and_index_documents, [file_upload], [upload_status])


if __name__ == "__main__":
    logger.info("Starting FRA RAG Web UI (Enhanced)...")
    logger.info("Features: Hybrid Search, Reranking, Caching, Feedback, Query History")
    logger.info("Open http://localhost:7860 in your browser")
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        css=custom_css,
    )
